VAERegressor(
  (conv1): Conv1d(20, 10, kernel_size=(3,), stride=(1,), padding=(1,))
  (bn1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv1d(10, 10, kernel_size=(3,), stride=(1,), padding=(1,))
  (bn2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv1d(10, 5, kernel_size=(3,), stride=(1,), padding=(1,))
  (bn3): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc_mu): Linear(in_features=250, out_features=5, bias=True)
  (fc_logvar): Linear(in_features=250, out_features=5, bias=True)
  (fc1): Linear(in_features=5, out_features=250, bias=True)
  (conv4): ConvTranspose1d(5, 10, kernel_size=(3,), stride=(1,), padding=(1,))
  (bn4): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): ConvTranspose1d(10, 20, kernel_size=(3,), stride=(1,), padding=(1,))
  (fc4): Linear(in_features=250, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
We apply the domain adaptation for s to m
Train shape (18224, 50, 20)
Test shape (30918, 50, 20)
Epoch 1/40, Train_RMSELoss: 0.2289, Test_RMSELoss:0.3479
Epoch 2/40, Train_RMSELoss: 0.1714, Test_RMSELoss:0.3491
Epoch 3/40, Train_RMSELoss: 0.1570, Test_RMSELoss:0.3918
Epoch 4/40, Train_RMSELoss: 0.1426, Test_RMSELoss:0.3638
Epoch 5/40, Train_RMSELoss: 0.1397, Test_RMSELoss:0.2768
Epoch 6/40, Train_RMSELoss: 0.1337, Test_RMSELoss:0.3555
Epoch 7/40, Train_RMSELoss: 0.1358, Test_RMSELoss:0.3621
Epoch 8/40, Train_RMSELoss: 0.1290, Test_RMSELoss:0.3378
Epoch 9/40, Train_RMSELoss: 0.1199, Test_RMSELoss:0.3260
Epoch 10/40, Train_RMSELoss: 0.1205, Test_RMSELoss:0.3179
Epoch 11/40, Train_RMSELoss: 0.1202, Test_RMSELoss:0.3225
Epoch 12/40, Train_RMSELoss: 0.1172, Test_RMSELoss:0.3117
Epoch 13/40, Train_RMSELoss: 0.1229, Test_RMSELoss:0.2858
Epoch 14/40, Train_RMSELoss: 0.1162, Test_RMSELoss:0.2927
Epoch 15/40, Train_RMSELoss: 0.1170, Test_RMSELoss:0.2644
Epoch 16/40, Train_RMSELoss: 0.1162, Test_RMSELoss:0.3113
Epoch 17/40, Train_RMSELoss: 0.1134, Test_RMSELoss:0.3162
Epoch 18/40, Train_RMSELoss: 0.1159, Test_RMSELoss:0.2648
Epoch 19/40, Train_RMSELoss: 0.1131, Test_RMSELoss:0.2883
Epoch 20/40, Train_RMSELoss: 0.1156, Test_RMSELoss:0.2743
Epoch 21/40, Train_RMSELoss: 0.1146, Test_RMSELoss:0.2573
Epoch 22/40, Train_RMSELoss: 0.1092, Test_RMSELoss:0.2926
Epoch 23/40, Train_RMSELoss: 0.1084, Test_RMSELoss:0.2700
Epoch 24/40, Train_RMSELoss: 0.1092, Test_RMSELoss:0.2475
Epoch 25/40, Train_RMSELoss: 0.1110, Test_RMSELoss:0.3013
Epoch 26/40, Train_RMSELoss: 0.1139, Test_RMSELoss:0.2829
Epoch 27/40, Train_RMSELoss: 0.1085, Test_RMSELoss:0.2885
Epoch 28/40, Train_RMSELoss: 0.1064, Test_RMSELoss:0.2649
Epoch 29/40, Train_RMSELoss: 0.1027, Test_RMSELoss:0.2446
Epoch 30/40, Train_RMSELoss: 0.1057, Test_RMSELoss:0.2690
Epoch 31/40, Train_RMSELoss: 0.1067, Test_RMSELoss:0.2915
Epoch 32/40, Train_RMSELoss: 0.1065, Test_RMSELoss:0.2690
Epoch 33/40, Train_RMSELoss: 0.1093, Test_RMSELoss:0.2741
Epoch 34/40, Train_RMSELoss: 0.1084, Test_RMSELoss:0.3047
Epoch 35/40, Train_RMSELoss: 0.1065, Test_RMSELoss:0.2676
Epoch 36/40, Train_RMSELoss: 0.1046, Test_RMSELoss:0.2558
Epoch 37/40, Train_RMSELoss: 0.1036, Test_RMSELoss:0.2537
Epoch 38/40, Train_RMSELoss: 0.1036, Test_RMSELoss:0.2969
Epoch 39/40, Train_RMSELoss: 0.1080, Test_RMSELoss:0.2482
Epoch 40/40, Train_RMSELoss: 0.1050, Test_RMSELoss:0.2632
{"Test Loss for unit 2": 17.787473678588867, "Test Loss for unit 3": 17.221590042114258, "Test Loss for unit 4": 15.228128433227539, "Test Loss for unit 7": 19.933382034301758, "Test Loss for unit 15": 15.643203735351562}